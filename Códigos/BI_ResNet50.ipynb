{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/antoniodragoc/Projeto-de-Graduacao-Antonio-Drago-Caetano/blob/main/3_ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BjjPrlamJQ7F"
   },
   "outputs": [],
   "source": [
    "# import the needed packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.metrics import Recall,AUC\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtUX-mzoSbYj",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "folder = 'D:/Users/N30090/OneDrive - ArcelorMittal/Pictures/Doutorado_img/'\n",
    "for filename in os.listdir(folder):\n",
    "        print(filename)\n",
    "        # Caminhos de treino e validaçção\n",
    "\n",
    "        # Obs - no diretório dados4 os dados estão separados em 75% treino 15% validação e 10% teste\n",
    "        path_train = folder+filename+'/train/'\n",
    "        path_val = folder+filename+'/val/'\n",
    "\n",
    "        batch_size = 20\n",
    "\n",
    "        # Gerando os dados a partir das imagens\n",
    "        train_datagen = ImageDataGenerator(    \n",
    "            rotation_range = 90,\n",
    "            vertical_flip = True,\n",
    "            horizontal_flip = True,\n",
    "            zoom_range=0.05,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            fill_mode = 'reflect',\n",
    "            samplewise_center = True,\n",
    "            samplewise_std_normalization = True\n",
    "        )\n",
    "\n",
    "        val_datagen = ImageDataGenerator(\n",
    "            samplewise_center = True,\n",
    "            samplewise_std_normalization = True\n",
    "            )\n",
    "\n",
    "\n",
    "        test_datagen = ImageDataGenerator(\n",
    "            samplewise_center = True,\n",
    "            samplewise_std_normalization = True\n",
    "            )\n",
    "\n",
    "        # dados de treino\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            path_train,\n",
    "            target_size = (256, 256),\n",
    "            batch_size= batch_size,\n",
    "            shuffle=True,\n",
    "            class_mode= 'categorical' \n",
    "        )\n",
    "\n",
    "        y_true = train_generator.classes\n",
    "        y_true\n",
    "\n",
    "        #dados de validação\n",
    "        val_generator = val_datagen.flow_from_directory(\n",
    "            path_val,\n",
    "            target_size = (256, 256),\n",
    "            batch_size= batch_size,  \n",
    "            shuffle=True,\n",
    "            class_mode='categorical'     \n",
    "        )\n",
    "\n",
    "        val_generator.classes\n",
    "\n",
    "        # Chamando a rede pré-treinada\n",
    "        conv_model = ResNet50(\n",
    "            #weights='imagenet', \n",
    "            include_top=False, \n",
    "            input_shape=(256,256,3))\n",
    "\n",
    "        first_freeze_layers = 20 #number of the first layers to freeze\n",
    "        for layer in conv_model.layers[0:first_freeze_layers]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        teste = keras.layers.Flatten()(conv_model.output)\n",
    "\n",
    "        # three hidden layers\n",
    "        teste = keras.layers.Dropout(0.4)(teste)\n",
    "        teste = keras.layers.Dense(128, activation='relu')(teste)\n",
    "        teste = keras.layers.Dense(64, activation='relu')(teste)\n",
    "\n",
    "        # final softmax layer with two categories\n",
    "        predictions = keras.layers.Dense(2, activation='softmax')(teste)\n",
    "\n",
    "        # creating the full model:\n",
    "        full_model = keras.models.Model(inputs=conv_model.input, outputs=predictions)\n",
    "\n",
    "        #full_model.summary()\n",
    "\n",
    "        #EARLY STOPPING ADICIONADO\n",
    "        # https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
    "        callback = keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=0,\n",
    "            patience=15,\n",
    "            verbose=0,\n",
    "            mode=\"min\",\n",
    "            baseline=None,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                 factor=0.1,\n",
    "                                                 patience=15)\n",
    "        \n",
    "        lr_schedule = keras.optimizers.schedules.CosineDecayRestarts(\n",
    "            initial_learning_rate = 0.001, \n",
    "            first_decay_steps = 500,\n",
    "            t_mul=2.4, \n",
    "            m_mul=1.3, \n",
    "            alpha=0.001, \n",
    "            name=None\n",
    "        )\n",
    "\n",
    "        # Compilando o modelo\n",
    "        full_model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer= keras.optimizers.SGD(learning_rate=lr_schedule),\n",
    "                          metrics=['accuracy',Recall(),'AUC'])\n",
    "\n",
    "        # Treinando o modelo com os dados de treino e teste\n",
    "        history = full_model.fit(\n",
    "            train_generator,\n",
    "            batch_size=len(train_generator),\n",
    "            validation_data = val_generator,\n",
    "            epochs = 25,\n",
    "            callbacks=[callback,reduce_lr_on_plateau]\n",
    "        )\n",
    "\n",
    "        # list all data in history\n",
    "        print(history.history.keys())\n",
    "        # summarize history for accuracy\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "        '''\n",
    "        # summarize history for auc\n",
    "        plt.plot(history.history['auc'])\n",
    "        plt.plot(history.history['val_auc'])\n",
    "        plt.title('Model auc')\n",
    "        plt.ylabel('auc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "        '''\n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        #dados de teste\n",
    "        path_test = folder+filename+'/test/'\n",
    "        test_generator =  test_datagen.flow_from_directory(\n",
    "            path_test,\n",
    "            target_size = (256, 256),\n",
    "            shuffle = False,\n",
    "            batch_size= batch_size,\n",
    "            class_mode='categorical' \n",
    "\n",
    "            )\n",
    "\n",
    "        from sklearn.metrics import confusion_matrix, classification_report\n",
    "        Y_pred = full_model.predict(test_generator)\n",
    "        y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "        cmvgg = confusion_matrix(test_generator.classes, y_pred )\n",
    "\n",
    "        print(classification_report(test_generator.classes, y_pred))\n",
    "\n",
    "        class_names = ['Benign','Malignant']\n",
    "        report = classification_report(test_generator.classes, y_pred,target_names=class_names, output_dict=True)\n",
    "        df = pd.DataFrame(report).transpose()\n",
    "        df_ = df[['precision', 'recall','f1-score']]\n",
    "        df_ = df_.loc[[\"Benign\", \"Malignant\",\"macro avg\"]]\n",
    "        df_.to_csv(filename+'_resnet50.csv')\n",
    "        df_.head(10)\n",
    "\n",
    "        from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "        import seaborn as sns\n",
    "\n",
    "        cm = confusion_matrix(test_generator.classes, y_pred)\n",
    "        #cm = [[24,11],[1,34]]\n",
    "        plt.figure(figsize=(5,5))\n",
    "        x_axis_labels = ['Benign','Malignant'] # labels for x-axis\n",
    "        y_axis_labels = ['Benign','Malignant'] # labels for y-axis\n",
    "        ax = sns.heatmap(cm, annot=True, fmt=\"d\",xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "        sns.set(font_scale=1.8)\n",
    "        plt.title('Confusion matrix RESNET50')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "        from sklearn.metrics import roc_curve,auc, roc_auc_score,confusion_matrix, classification_report\n",
    "\n",
    "        fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_generator.classes, y_pred)\n",
    "        auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "        plt.xlabel('False positive rate')\n",
    "        plt.ylabel('True positive rate')\n",
    "        plt.title('ROC curve')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "3 - ResNet50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
